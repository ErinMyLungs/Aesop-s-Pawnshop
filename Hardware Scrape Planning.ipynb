{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "    import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import scipy.stats as stats\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Daily TODO:\n",
    "* figure out how to pull out pricing data from json\n",
    "* \n",
    "\n",
    "\n",
    "\n",
    "# Current TODO\n",
    "## Wikipedia name portion\n",
    "### nvidia: \n",
    "1. ~~Scrape NVIDIA GPU names~~\n",
    "1. ~~Clean-up nvidia gpu names~~\n",
    "1. ~~Drop nvidia names for gpus that aren't relevant (quadro/tesla/mobile cards)~~\n",
    "    * Note: this was done very fast and rough. This should be done cleaner but who cares right now\n",
    "1. Possibly cull names from gpus before 2007?\n",
    "    * These are unlikely to show up in secondary markets anyway?\n",
    "    * Culled tesla/scientific gpus cuz reasons\n",
    "    \n",
    "### AMD\n",
    "1. Scrape names\n",
    "    * Table format slightly differently.\n",
    "    * Pulled the 500 gen cards when using same scrape func\n",
    "1. Clean up names\n",
    "1. Drop irrelevant gpus\n",
    "    * it's worth doing this but right now focus on nvidia so we have some data\n",
    "\n",
    "### Questions and problems\n",
    "* Should we be scraping more information?\n",
    "    * date introduced\n",
    "    * features?\n",
    "    * ram?\n",
    "\n",
    "# Scrape Reddit\n",
    "1. ~~Scrape /r/hardwareswap with praw~~\n",
    "    * Where do we put this?\n",
    "    * Mongosdb!\n",
    "1. ~~Pull all info from posts that contain substring~~\n",
    "    * how do we ensure we're not pulling stuff like ssds?\n",
    "1. Compile times, price, and numbers\n",
    "    * this should give us a basic graph of model to price\n",
    "\n",
    "# Craigslist\n",
    "1. Scrape computer equipment/computer section\n",
    "1. Get price data\n",
    "\n",
    "# Amazon\n",
    "1. Scrape price data if possible"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Today\n",
    "* Dump results from reddit into mongosdb - how do I do this??"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}